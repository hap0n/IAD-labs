{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score, make_scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Побудувати моделi регресiї згiдно з варiантом.\n",
    "2. Виконати прогнози на основi побудованих моделей.\n",
    "3. Для кожної з моделей оцiнити, чи має мiсце перенавчання.\n",
    "4. Розрахувати додатковi результати моделей, наприклад, апостерiорнi iмовiрностi, опорнi вектори або iншi (згiдно з варiантом).\n",
    "7. В задачах регресiї розрахувати критерiї якостi для кожної моделi окремо\n",
    "на навчальнiй та перевiрочнiй множинах:\n",
    "- коефiцiєнт детермiнацiї R2\n",
    "- помилки RMSE, MAE та MAPE.\n",
    "8. Виконати решiтчастий пошук (grid search) для пiдбору гiперпараметрiв\n",
    "моделей.\n",
    "9. Зробити висновки про якiсть роботи моделей на дослiджених даних. На\n",
    "основi критерiїв якостi вибрати найкращу модель.\n",
    "10. Навчити моделi на пiдмножинах навчальних даних. Оцiнити, наскiльки\n",
    "розмiр навчальної множини впливає на якiсть моделi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get metrics without cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "lin_reg_metrics = {\n",
    "    \"rmse\": mean_squared_error(y_test, y_pred, squared=False),\n",
    "    \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "    \"mape\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "    \"r2\": r2_score(y_test, y_pred)\n",
    "}\n",
    "lin_reg_metrics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and create scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# scoring for models\n",
    "scoring={\n",
    "    \"rmse\": make_scorer(root_mean_squared_error, greater_is_better=False),\n",
    "    \"mae\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"mape\": make_scorer(mean_absolute_percentage_error, greater_is_better=False),\n",
    "    \"r2\": make_scorer(r2_score, greater_is_better=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(*args, **kwargs):\n",
    "    return mean_squared_error(squared=False, *args, **kwargs)\n",
    "\n",
    "def get_metrics(model, X=X, y=y, scoring=scoring, cv=10, get_mean=True):\n",
    "    metrics = cross_validate(model, X, y, scoring=scoring, cv=cv)\n",
    "    metrics = {k: np.abs(v) for k, v in metrics.items()}\n",
    "    metrics_mean = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    \n",
    "    ret_val = metrics_mean if get_mean else metrics\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': 0.000648331642150879,\n",
       " 'score_time': 0.0007868289947509765,\n",
       " 'test_rmse': 54.40461553640237,\n",
       " 'test_mae': 44.22301077001687,\n",
       " 'test_mape': 0.39455077012294637,\n",
       " 'test_r2': 0.461962361958337}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': 0.0006236553192138672,\n",
       " 'score_time': 0.000793004035949707,\n",
       " 'test_rmse': 55.79111301890865,\n",
       " 'test_mae': 46.24495525021393,\n",
       " 'test_mape': 0.42058494897932996,\n",
       " 'test_r2': 0.44180819270734994}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(Ridge(alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression model with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}